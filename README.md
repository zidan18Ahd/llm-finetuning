This repository documents my step by step journey into Large Language Model (LLM) fine tuning, starting from basic full parameter training on small open source models and gradually moving toward parameter efficient and alignment techniques.
The goal is to understand LLM training fundamentals deeply before applying optimization methods such as PEFT, LoRA, QLoRA, and RLHF.
